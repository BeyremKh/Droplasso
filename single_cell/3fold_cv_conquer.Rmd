---
title: "New_droplasso_conquer"
output: html_document
---

```{r setup, include=FALSE}

library(SummarizedExperiment)
library(MultiAssayExperiment)
library(knitr)
library(survival)
library(glmnet)
library(Matrix)
library(parallel)
require(mvtnorm)
library(ggplot2)
library(droplasso)
#subsample 
subsample <- function(xtrain,m) 
{dev=lapply(1:ncol(xtrain), function(x) sd(xtrain[,x]))
sortedev=sort(unlist(dev))
xtrainb=xtrain[,which(dev > sortedev[length(sortedev)-m])]
return(xtrainb)}
```

## Introduction


Given training dataset x with labeles y, droplasso solves the following optimization problem 
\begin{equation}
 \underset{w \in \mathbb{R}^d}{min}  \left ( R_{dropLasso} (x,y,w)  \right ) = \underset{w \in \mathbb{R}^d}{min}   \underset{\delta_1,...,\delta_n \sim B(p)}{ \mathbb {E}} ?\left( \frac{1}{n} \sum_{i=1}^{n}L(y_{i}, w^{\top} (\mathbf{\delta_{i}}  \odot x_{i,}))   +  \lambda .  \left \| w\right \|_{1} \right) 
\end{equation}

We want to compare the performance of the DropLasso with ElasticNet using the Conquer database 

## Data processing
Data is downloaded from the conquer database website [conquer](http://imlspenticton.uzh.ch:3838/conquer/). For each dataset we:
1. Select the count_lstpm normalized gene expression. 
2. Select a binary label from the set of pghenotypes in the annotations in the dataset. 
3. Subsample the dataset according to the label (usually balanced, if not take the min)
4. Remove genes that are not expressed for those samples (0 norm)
5. We create 5-folds with a 1/5 th of the data for training, 1/5 th for validation (selection of the best parameters), and the remaining 3/5th for testing the accuracy (AUC). 


We show the preproccessing step below on EMTAB2805: 
```{r prepareEMTAB2805, eval=FALSE}

EMTAB2805 <- readRDS("EMTAB2805.rds")

(EMTAB2805_gene <- experiments(EMTAB2805)[["gene"]])
data_count= t(assays(EMTAB2805_gene)[["count"]])
data_lstpm= t(assays(EMTAB2805_gene)[["count_lstpm"]])

pdata <- colData(EMTAB2805)

pos=which(pdata$cell_cycle_stage=="G1")
neg=which(pdata$cell_cycle_stage=="S")
y= c(rep(0,length(pos)),rep(1,length(neg)))
 
norm_data=sapply(1:ncol(data_lstpm),function(i) norm(as.matrix(data_lstpm[,i])))
data_lstpm=data_lstpm[,-which(norm_data==0)]


xtrain_lstpm= data_lstpm[c(pos,neg),] 
xtrain_count=data_count[c(pos,neg),]


#We use count_lstpm and normalize

n=nrow(xtrain_lstpm)
nrepeats <- 2
nfolds <- 5
folds <- list()
for (i in seq(nrepeats)) {
    folds <- c(folds,split(sample(seq(n)), rep(1:nfolds, length = n)))
}

for (i in 1:10)
{ itrain=folds[[i]]
norm_data=sapply(1:ncol(xtrain_lstpm[itrain,]),function(i) norm(as.matrix(xtrain_lstpm[itrain,i])))
xtrain_lstpm=xtrain_lstpm[,-which(norm_data==0)]
}
xtrain=scale(xtrain_lstpm,center=F)

#xtrain=subsample(xtrain_lstpm,100)

plot(cv.glmnet(xtrain,y,family="binomial",type.measure="auc",lambda=seqlambda,standardize=F,intercept=F))


save(xtrain,folds,y,file="EMTAB2805_lstpm_all.Rdata")

```

The datasets selected are : 
- EMTAB2805
- GSE45719
- GSE63818
- GSE48968

## Cross validation procedure and example

The cross validation is done in parallel on a cluster for each fold and each parameter. Code can be seen in this markdown (here we use directly the Cfunction in the package droplasso for matter of convenience with this particular cluster).
Elastic net and DropLasso both have two parameters.We vary the Elasticnet $\lambda_{el}$ parameter over a large grid of $100$ values, and  $\alpha_{el}$ over 10 regularly spaced values between $0$ and $1$, estimate the classification performance on the test set in terms of area under the receiving operator curve (AUC), and report the best average AUC over the grid of the two parameters. We do the same for DropLasso after transformation of the values of the two parameters using the equations system in the paper, in order to have a fair comparaison in the same parameters space. 
Here is an example of the wrapper function used to evaluate the accuracy for one fold, and a set of parameters.
```{r cluster,eval=F}
library(glmnet)
library(Matrix)
library(ROCR)
library(mvtnorm)
library(survival)

load("/cbio/donnees/bkhalfaoui/cluster/EMTAB2805_lstpm_all.Rdata")

Rcpp::sourceCpp('/cbio/donnees/bkhalfaoui/cluster/Cfunctions.cpp')

options(echo=FALSE ) # if you want see commands in output file
args <- commandArgs(trailingOnly = TRUE)

seqlambda=c(as.vector(sapply(-20:78,function(j) 10^(-0.1*j) )),0)
seqalpha=rev(c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1))


# Main loop (done in parallel on several cores)
accuracy <- function(iexp,ind1,ind2)
{   xtrain=scale(xtrain,center=F)
    n=nrow(xtrain)
    d=ncol(xtrain)
itrain <- folds[[iexp]]
ival= folds[[(iexp+1)%%10]]


# penalized elasticnet

m_glm=glmnet(xtrain[itrain,],y[itrain],family="binomial",lambda=seqlambda[ind1],alpha=seqalpha[ind2],intercept = F,standardize = F)
ypred <- (xtrain[ival,]) %*% m_glm$beta
pred <- prediction(ypred[,1],y[ival])
auc_el_val_val <- performance(pred, "auc")@y.values[[1]]
a_el_val=length(which(m_glm$beta[,1]==0))



ypred <- (xtrain[-c(ival,itrain),]) %*% m_glm$beta
pred <- prediction(ypred[,1],y[-c(itrain,ival)])
auc_el_val <- performance(pred, "auc")@y.values[[1]]
a_el=length(which(m_glm$beta[,1]==0))


m <- droplassoC(xtrain[itrain,],y[itrain],family="binomial",1/(1+seqlambda[ind1]*(1-seqalpha[ind2])/2),seqlambda[ind1]*seqalpha[ind2],rnorm(d,0,0.1),1,100000,length(itrain))

ypred <- (xtrain[ival,]) %*% m
pred <- prediction(ypred[,1],y[ival])
auc_dl_val_val <- performance(pred, "auc")@y.values[[1]]
a_dl_val=length(which(m==0))

ypred <- (xtrain[-c(ival,itrain),]) %*% m
pred <- prediction(ypred[,1],y[-c(itrain,ival)])
auc_dl_val <- performance(pred, "auc")@y.values[[1]]
a_dl=length(which(m==0))

  
acc=c(auc_el_val_val,auc_el_val,auc_dl_val_val,auc_dl_val,a_el_val,a_el,a_dl_val,a_dl,seqlambda[ind1],seqalpha[ind2],iexp)
return(acc)
}

filename=paste("/cbio/donnees/bkhalfaoui/Results/auc_EMTAB2805_lstpm_all_val",args[1],args[2],args[3],".Rdata",sep="")
acc_simul=accuracy(as.numeric(args[1]),as.numeric(args[2]),as.numeric(args[3]))
save(acc_simul,file=filename)


```


## Results 

Here we plot the test AUC of droplasso a  nd ElasticNet as a function of the number of variables selected by the model (results are produced by the above code ran in the cluster).

Here is the plot with the test AUC for the original datasets for the corresponding methods: 
```{r results_synthesis, echo=FALSE}
all_auc_el=rep(0,6)
all_auc_dl=rep(0,6)
all_auc_l=rep(0,6)
all_auc_dr=rep(0,6)
datanames= c("EMTAB2805_S_G1","EMTAB2805","GSE45719_16_8","GSE63818_7_10","GSE48968","GSE48968_4_6")
load("results/auc_EMTAB2805_lstpm_all_S_G1_val_p.Rdata")
all_auc_el[1]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[1]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[1]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[1]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

load("results/auc_EMTAB2805_lstpm_all_val_p.Rdata")
all_auc_el[2]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[2]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[2]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[2]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

load("results/auc_GSE45719_lstpm_all_16_8_val_p.Rdata")
all_auc_el[3]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[3]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[3]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[3]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

load("results/auc_GSE63818_lstpm_all_7_10_val_p.Rdata")
all_auc_el[4]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[4]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[4]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[4]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

load("results/auc_GSE48968_lstpm_all_val_p.Rdata")
all_auc_el[5]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[5]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[5]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[5]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

load("results/auc_GSE48968_lstpm_all_4_6_val_p.Rdata")
all_auc_el[6]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[,1])),1]
all_auc_dl[6]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[,1])),1]
all_auc_l[6]=auc_el_test[which(auc_el_val[,1]==max(auc_el_val[seq(1,1000,10),1])),1]
all_auc_dr[6]=auc_dl_test[which(auc_dl_val[,1]==max(auc_dl_val[seq(1,1000,10),1])),1]

print(rbind(c("data","Lasso","dropout","ElasticNet","DropLasso"),cbind(datanames,round(all_auc_l,digits=3),round(all_auc_dr,digits=3),round(all_auc_el,digits = 3),round(all_auc_dl,digits=3))))

boxplot(cbind(all_auc_l,all_auc_dr,all_auc_el,all_auc_dl),col=rainbow(4),xaxt='n',ylab='AUC')
axis(side=1,1:4,c("Lasso","dropout", "ElasticNet","DropLasso"))

```

